{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from statsmodels.tsa.seasonal import STL\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select file\n",
    "fol = '../offline_data/mlwwcoast_prep_data'\n",
    "myvar = 'u'\n",
    "bb = 0\n",
    "back = 24\n",
    "forward = 24\n",
    "fload = '{:s}/input_{:s}_buoy{:d}_back{:d}_for{:d}.npz'.format(fol,myvar,bb,back,forward)\n",
    "D = np.load(fload)\n",
    "\n",
    "# Keys in D\n",
    "# X -> History Matrix (time,hr-back) where hr-back = 0,1,2,...\n",
    "# Y -> Labels, (time,hr-forward) where hr_forward = 1,2,3... (pred we are trying to make)\n",
    "# F -> Weather Forecast, (time,hr-forward)\n",
    "# t -> time (time,)\n",
    "# avg -> daily average, smoothed (time,1)\n",
    "\n",
    "# stl = STL(co2, seasonal=13)\n",
    "# res = stl.fit()\n",
    "# fig = res.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-18ce21d3610a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m#plt.plot(s)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mstatsmodels\\tsa\\_stl.pyx\u001b[0m in \u001b[0;36mstatsmodels.tsa._stl.STL.fit\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "D['Y'].shape\n",
    "s = D['Y'][:,0]\n",
    "\n",
    "period = 24*365\n",
    "\n",
    "stl = STL(s, period=period)\n",
    "\n",
    "#plt.plot(s)\n",
    "res = stl.fit()\n",
    "fig = res.plot()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on buoy {:d} 0\n",
      "Working on buoy {:d} 1\n",
      "Working on buoy {:d} 2\n",
      "Working on buoy {:d} 3\n",
      "Working on buoy {:d} 4\n",
      "Working on buoy {:d} 5\n",
      "Working on buoy {:d} 6\n",
      "Working on buoy {:d} 7\n",
      "Working on buoy {:d} 8\n",
      "Working on buoy {:d} 9\n",
      "Working on buoy {:d} 10\n",
      "Working on buoy {:d} 11\n",
      "Working on buoy {:d} 12\n",
      "Working on buoy {:d} 13\n",
      "Working on buoy {:d} 14\n",
      "Working on buoy {:d} 15\n",
      "Working on buoy {:d} 16\n",
      "Working on buoy {:d} 17\n",
      "Working on buoy {:d} 18\n",
      "Working on buoy {:d} 19\n",
      "Working on buoy {:d} 20\n",
      "Time elapsed: 5514.5 seconds\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../offline_data/mlwwcoast_outputs/20211128_v_rmse.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-baa07c9a01df>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;31m# Save rmse's\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[0mfname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'../../offline_data/mlwwcoast_outputs/20211128_{:s}_rmse'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmyvar\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m np.savez(fname, lr_te=lr_rmse_te, lr_tr=lr_rmse_tr, mr_tr=mr_rmse_tr, mr_te = mr_rmse_te,\n\u001b[0m\u001b[0;32m    100\u001b[0m         \u001b[0mbuoys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdo_buoys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhours\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdo_hours\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         ref_te=ref_rmse_te, ref_tr=ref_rmse_tr)\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msavez\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36msavez\u001b[1;34m(file, *args, **kwds)\u001b[0m\n\u001b[0;32m    615\u001b[0m     \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m9\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    616\u001b[0m     \"\"\"\n\u001b[1;32m--> 617\u001b[1;33m     \u001b[0m_savez\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    618\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    619\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36m_savez\u001b[1;34m(file, args, kwds, compress, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[0;32m    711\u001b[0m         \u001b[0mcompression\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mZIP_STORED\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    712\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 713\u001b[1;33m     \u001b[0mzipf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzipfile_factory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"w\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnamedict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mzipfile_factory\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[1;32mimport\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'allowZip64'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[0;32m   1249\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1250\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1251\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1252\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1253\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../offline_data/mlwwcoast_outputs/20211128_v_rmse.npz'"
     ]
    }
   ],
   "source": [
    "# Loop over\n",
    "# 1. buoy\n",
    "# 2. forecast hour\n",
    "# What to show relative skill to weather prediction\n",
    "\n",
    "def test_model(model, X, y):\n",
    "    x_tr, x_te, y_tr, y_te = train_test_split(X, y, test_size = 0.25, random_state = 42)\n",
    "    model.fit(x_tr, y_tr)\n",
    "    y_p = model.predict(x_te)\n",
    "    y_tr_p = model.predict(x_tr)\n",
    "    rmse_te = np.sqrt(np.mean(np.power(y_p-y_te,2)))\n",
    "    rmse_tr = np.sqrt(np.mean(np.power(y_tr_p-y_tr,2)))\n",
    "    return (rmse_te,rmse_tr)\n",
    "\n",
    "# Set path to save data folder\n",
    "fol = '../offline_data/mlwwcoast_prep_data'\n",
    "fol_model = '../offline_data/mlwwcoast_models'\n",
    "\n",
    "# How many buoys/hours to do\n",
    "do_buoys = range(21)\n",
    "do_hours = range(12)\n",
    "Nb = len(do_buoys)\n",
    "Nh = len(do_hours)\n",
    "\n",
    "# Save rmse scores\n",
    "lr_rmse_te = np.zeros((Nb,Nh))\n",
    "lr_rmse_tr = np.zeros((Nb,Nh))\n",
    "mr_rmse_te = np.zeros((Nb,Nh))\n",
    "mr_rmse_tr = np.zeros((Nb,Nh))\n",
    "\n",
    "ref_rmse_te = np.zeros(Nb)\n",
    "ref_rmse_tr = np.zeros(Nb)\n",
    "\n",
    "# Loop\n",
    "start_time = time.time()\n",
    "for bb in do_buoys:\n",
    "    \n",
    "    print('Working on buoy {:d}',bb)\n",
    "    \n",
    "    for ff in do_hours:\n",
    "\n",
    "        # Select with variable to predict\n",
    "        myvar = 'v' \n",
    "\n",
    "        # Data load parameters\n",
    "        back = 24 # Select how many hours to go back in time\n",
    "        forward = 24 # Select forecast hour to predict\n",
    "\n",
    "        # Select file\n",
    "        fload = '{:s}/input_{:s}_buoy{:d}_back{:d}_for{:d}.npz'.format(fol,myvar,bb,back,forward)\n",
    "        D = np.load(fload)\n",
    "\n",
    "        # Keys in D\n",
    "        # X -> History Matrix (time,hr-back) where hr-back = 0,1,2,...\n",
    "        # Y -> Labels, (time,hr-forward) where hr_forward = 1,2,3... (pred we are trying to make)\n",
    "        # F -> Weather Forecast, (time,hr-forward)\n",
    "        # t -> time (time,)\n",
    "        # avg -> daily average, smoothed (time,1)\n",
    "\n",
    "        # Regression Settings\n",
    "        hr_for = ff\n",
    "        hr_back = 24\n",
    "\n",
    "        # Make input\n",
    "        X = D['X'][:,1:hr_back]\n",
    "        f = D['F'][:,hr_for]\n",
    "        f = np.expand_dims(f,1)\n",
    "        X = np.concatenate((X,D['avg']),axis=1)\n",
    "        X = np.concatenate((X,f),axis=1)\n",
    "\n",
    "        # Make labels\n",
    "        y = D['Y'][:,hr_for]\n",
    "\n",
    "        # Train/Test Set\n",
    "        x_tr, x_te, y_tr, y_te = train_test_split(X, y, test_size = 0.25, random_state = 42)\n",
    "\n",
    "        # Skill of numerical weather model\n",
    "        ref_rmse_te[bb] = np.sqrt(np.mean(np.power(y_te-x_te[:,24],2)))\n",
    "        ref_rmse_tr[bb] = np.sqrt(np.mean(np.power(y_tr-x_tr[:,24],2)))\n",
    "\n",
    "        # Train models\n",
    "        model = LinearRegression()\n",
    "        (lr_rmse_te[bb,ff],lr_rmse_tr[bb,ff]) = test_model(model, X, y)\n",
    "        # save the model to disk\n",
    "        fname = '{:s}/lr_{:s}_buoy{:d}_back{:d}_for{:d}'.format(fol_model,myvar,bb,back,forward)\n",
    "        pickle.dump(model, open(fname, 'wb'))\n",
    "        \n",
    "        model = MLPRegressor(random_state=1, max_iter=500, hidden_layer_sizes=25)\n",
    "        (mr_rmse_te[bb,ff],mr_rmse_tr[bb,ff]) = test_model(model, X, y)\n",
    "        # save the model to disk\n",
    "        fname = '{:s}/mlp_{:s}_buoy{:d}_back{:d}_for{:d}'.format(fol_model,myvar,bb,back,forward)\n",
    "        pickle.dump(model, open(fname, 'wb'))\n",
    "\n",
    "end_time = time.time()\n",
    "print('Time elapsed: {:4.1f} seconds'.format(end_time-start_time))\n",
    "\n",
    "# Save rmse's\n",
    "fname = '../offline_data/mlwwcoast_outputs/20211128_{:s}_rmse'.format(myvar)\n",
    "np.savez(fname, lr_te=lr_rmse_te, lr_tr=lr_rmse_tr, mr_tr=mr_rmse_tr, mr_te = mr_rmse_te,\n",
    "        buoys=do_buoys, hours=do_hours,\n",
    "        ref_te=ref_rmse_te, ref_tr=ref_rmse_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save rmse's\n",
    "fname = '../offline_data/mlwwcoast_outputs/20211128_{:s}_rmse'.format(myvar)\n",
    "np.savez(fname, lr_te=lr_rmse_te, lr_tr=lr_rmse_tr, mr_tr=mr_rmse_tr, mr_te = mr_rmse_te,\n",
    "        buoys=do_buoys, hours=do_hours,\n",
    "        ref_te=ref_rmse_te, ref_tr=ref_rmse_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BELOW IS EXTRA, stop here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelectHours(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, hr_back=24):        \n",
    "        self.hr_back = hr_back\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self,X):\n",
    "        return X[:,1:hr_back-1]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "my_pipeline = Pipeline([\n",
    "    ('selecthours',SelectHours(hr_back=24)),\n",
    "    #('std_scaler',StandardScaler()),\n",
    "])\n",
    "\n",
    "X_prepared = my_pipeline.fit_transform(X)\n",
    "\n",
    "LR = LinearRegression()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6302,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [1.43843141 1.42331392 1.13114424 1.85759804 1.68825704 1.2717601\n",
      " 1.73177701 1.94795364 1.02712141 1.50835131]\n",
      "Mean: 1.502570812794681\n",
      "Std: 0.2896786849242856\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(LR, X, y, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "lr_rmse_scores = np.sqrt(-scores)\n",
    "\n",
    "def display_scores(scores):\n",
    "    print('Scores:', scores)\n",
    "    print('Mean:',scores.mean())\n",
    "    print('Std:',scores.std())\n",
    "    \n",
    "display_scores(lr_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(min_samples_split=100)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "forest_reg = RandomForestRegressor(n_estimators=100,min_samples_split=100)\n",
    "forest_reg.fit(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2622097237533456\n"
     ]
    }
   ],
   "source": [
    "y_p = forest_reg.predict(X)\n",
    "rmse = np.sqrt(np.mean(np.power(y_p-y,2)))\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(forest_reg, X, y, scoring=\"neg_mean_squared_error\", cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [1.50583425 1.56661999 1.52521674 1.92240661 1.30423861]\n",
      "Mean: 1.5648632396390894\n",
      "Std: 0.20041048609207965\n"
     ]
    }
   ],
   "source": [
    "lr_rmse_scores = np.sqrt(-scores)\n",
    "display_scores(lr_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(hidden_layer_sizes=25, max_iter=500, random_state=1)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tr, x_te, y_tr, y_te = train_test_split(X, y, test_size = 0.25, random_state = 42)\n",
    "reg_mlp = MLPRegressor(random_state=1, max_iter=500, hidden_layer_sizes=25)\n",
    "reg_mlp.fit(x_tr,y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5114376161412741\n"
     ]
    }
   ],
   "source": [
    "y_p = reg_mlp.predict(x_te)\n",
    "rmse = np.sqrt(np.mean(np.power(y_p-y_te,2)))\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4430444371323001\n"
     ]
    }
   ],
   "source": [
    "y_p = reg_mlp.predict(x_tr)\n",
    "rmse = np.sqrt(np.mean(np.power(y_p-y_tr,2)))\n",
    "print(rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
