{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import pickle\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.neural_network import MLPRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on buoy {:d} 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:587: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on buoy {:d} 1\n",
      "Working on buoy {:d} 2\n",
      "Working on buoy {:d} 3\n",
      "Working on buoy {:d} 4\n",
      "Working on buoy {:d} 5\n",
      "Working on buoy {:d} 6\n"
     ]
    }
   ],
   "source": [
    "# Loop over\n",
    "# 1. buoy\n",
    "# 2. forecast hour\n",
    "# What to show relative skill to weather prediction\n",
    "\n",
    "def test_model(model, X, y):\n",
    "    x_tr, x_te, y_tr, y_te = train_test_split(X, y, test_size = 0.25, random_state = 42)\n",
    "    model.fit(x_tr, y_tr)\n",
    "    y_p = model.predict(x_te)\n",
    "    y_tr_p = model.predict(x_tr)\n",
    "    rmse_te = np.sqrt(np.mean(np.power(y_p-y_te,2)))\n",
    "    rmse_tr = np.sqrt(np.mean(np.power(y_tr_p-y_tr,2)))\n",
    "    return (rmse_te,rmse_tr)\n",
    "\n",
    "# Set path to save data folder\n",
    "fol = '../offline_data/mlwwcoast_prep_data'\n",
    "fol_model = '../offline_data/mlwwcoast_models'\n",
    "\n",
    "# How many buoys/hours to do\n",
    "do_buoys = range(21)\n",
    "do_hours = range(12)\n",
    "Nb = len(do_buoys)\n",
    "Nh = len(do_hours)\n",
    "\n",
    "# Save rmse scores\n",
    "lr_rmse_te = np.zeros((Nb,Nh))\n",
    "lr_rmse_tr = np.zeros((Nb,Nh))\n",
    "mr_rmse_te = np.zeros((Nb,Nh))\n",
    "mr_rmse_tr = np.zeros((Nb,Nh))\n",
    "\n",
    "ref_rmse_te = np.zeros(Nb)\n",
    "ref_rmse_tr = np.zeros(Nb)\n",
    "\n",
    "# Loop\n",
    "start_time = time.time()\n",
    "for bb in do_buoys:\n",
    "    \n",
    "    print('Working on buoy {:d}',bb)\n",
    "    \n",
    "    for ff in do_hours:\n",
    "\n",
    "        # Select with variable to predict\n",
    "        myvar = 'v' \n",
    "\n",
    "        # Data load parameters\n",
    "        back = 24 # Select how many hours to go back in time\n",
    "        forward = 24 # Select forecast hour to predict\n",
    "\n",
    "        # Select file\n",
    "        fload = '{:s}/input_{:s}_buoy{:d}_back{:d}_for{:d}.npz'.format(fol,myvar,bb,back,forward)\n",
    "        D = np.load(fload)\n",
    "\n",
    "        # Keys in D\n",
    "        # X -> History Matrix (time,hr-back) where hr-back = 0,1,2,...\n",
    "        # Y -> Labels, (time,hr-forward) where hr_forward = 1,2,3... (pred we are trying to make)\n",
    "        # F -> Weather Forecast, (time,hr-forward)\n",
    "        # t -> time (time,)\n",
    "        # avg -> daily average, smoothed (time,1)\n",
    "\n",
    "        # Regression Settings\n",
    "        hr_for = ff\n",
    "        hr_back = 24\n",
    "\n",
    "        # Make input\n",
    "        X = D['X'][:,1:hr_back]\n",
    "        f = D['F'][:,hr_for]\n",
    "        f = np.expand_dims(f,1)\n",
    "        X = np.concatenate((X,D['avg']),axis=1)\n",
    "        X = np.concatenate((X,f),axis=1)\n",
    "\n",
    "        # Make labels\n",
    "        y = D['Y'][:,hr_for]\n",
    "\n",
    "        # Train/Test Set\n",
    "        x_tr, x_te, y_tr, y_te = train_test_split(X, y, test_size = 0.25, random_state = 42)\n",
    "\n",
    "        # Skill of numerical weather model\n",
    "        ref_rmse_te[bb] = np.sqrt(np.mean(np.power(y_te-x_te[:,24],2)))\n",
    "        ref_rmse_tr[bb] = np.sqrt(np.mean(np.power(y_tr-x_tr[:,24],2)))\n",
    "\n",
    "        # Train models\n",
    "        model = LinearRegression()\n",
    "        (lr_rmse_te[bb,ff],lr_rmse_tr[bb,ff]) = test_model(model, X, y)\n",
    "        # save the model to disk\n",
    "        fname = '{:s}/lr_{:s}_buoy{:d}_back{:d}_for{:d}'.format(fol_model,myvar,bb,back,forward)\n",
    "        pickle.dump(model, open(fname, 'wb'))\n",
    "        \n",
    "        model = MLPRegressor(random_state=1, max_iter=500, hidden_layer_sizes=25)\n",
    "        (mr_rmse_te[bb,ff],mr_rmse_tr[bb,ff]) = test_model(model, X, y)\n",
    "        # save the model to disk\n",
    "        fname = '{:s}/mlp_{:s}_buoy{:d}_back{:d}_for{:d}'.format(fol_model,myvar,bb,back,forward)\n",
    "        pickle.dump(model, open(fname, 'wb'))\n",
    "\n",
    "end_time = time.time()\n",
    "print('Time elapsed: {:4.1f} seconds'.format(end_time-start_time))\n",
    "\n",
    "# Save rmse's\n",
    "fname = '../offline_data/mlwwcoast_outputs/20211128_{:s}_rmse'.format(myvar)\n",
    "np.savez(fname, lr_te=lr_rmse_te, lr_tr=lr_rmse_tr, mr_tr=mr_rmse_tr, mr_te = mr_rmse_te,\n",
    "        buoys=do_buoys, hours=do_hours,\n",
    "        ref_te=ref_rmse_te, ref_tr=ref_rmse_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save rmse's\n",
    "fname = '../offline_data/mlwwcoast_outputs/20211128_{:s}_rmse'.format(myvar)\n",
    "np.savez(fname, lr_te=lr_rmse_te, lr_tr=lr_rmse_tr, mr_tr=mr_rmse_tr, mr_te = mr_rmse_te,\n",
    "        buoys=do_buoys, hours=do_hours,\n",
    "        ref_te=ref_rmse_te, ref_tr=ref_rmse_tr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BELOW IS EXTRA, stop here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelectHours(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, hr_back=24):        \n",
    "        self.hr_back = hr_back\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self,X):\n",
    "        return X[:,1:hr_back-1]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "my_pipeline = Pipeline([\n",
    "    ('selecthours',SelectHours(hr_back=24)),\n",
    "    #('std_scaler',StandardScaler()),\n",
    "])\n",
    "\n",
    "X_prepared = my_pipeline.fit_transform(X)\n",
    "\n",
    "LR = LinearRegression()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6302,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [1.43843141 1.42331392 1.13114424 1.85759804 1.68825704 1.2717601\n",
      " 1.73177701 1.94795364 1.02712141 1.50835131]\n",
      "Mean: 1.502570812794681\n",
      "Std: 0.2896786849242856\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(LR, X, y, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "lr_rmse_scores = np.sqrt(-scores)\n",
    "\n",
    "def display_scores(scores):\n",
    "    print('Scores:', scores)\n",
    "    print('Mean:',scores.mean())\n",
    "    print('Std:',scores.std())\n",
    "    \n",
    "display_scores(lr_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(min_samples_split=100)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "forest_reg = RandomForestRegressor(n_estimators=100,min_samples_split=100)\n",
    "forest_reg.fit(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2622097237533456\n"
     ]
    }
   ],
   "source": [
    "y_p = forest_reg.predict(X)\n",
    "rmse = np.sqrt(np.mean(np.power(y_p-y,2)))\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(forest_reg, X, y, scoring=\"neg_mean_squared_error\", cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [1.50583425 1.56661999 1.52521674 1.92240661 1.30423861]\n",
      "Mean: 1.5648632396390894\n",
      "Std: 0.20041048609207965\n"
     ]
    }
   ],
   "source": [
    "lr_rmse_scores = np.sqrt(-scores)\n",
    "display_scores(lr_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(hidden_layer_sizes=25, max_iter=500, random_state=1)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tr, x_te, y_tr, y_te = train_test_split(X, y, test_size = 0.25, random_state = 42)\n",
    "reg_mlp = MLPRegressor(random_state=1, max_iter=500, hidden_layer_sizes=25)\n",
    "reg_mlp.fit(x_tr,y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5114376161412741\n"
     ]
    }
   ],
   "source": [
    "y_p = reg_mlp.predict(x_te)\n",
    "rmse = np.sqrt(np.mean(np.power(y_p-y_te,2)))\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4430444371323001\n"
     ]
    }
   ],
   "source": [
    "y_p = reg_mlp.predict(x_tr)\n",
    "rmse = np.sqrt(np.mean(np.power(y_p-y_tr,2)))\n",
    "print(rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
